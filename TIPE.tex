\documentclass[10pt,a4paper,titlepage]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{float}
\title{Les Réseaux de Neurones}
\author{Philibert PAPPENS, Tristan POIDATZ, Mathurin PETIT}
\date{2021-2022}
\begin{document}
\maketitle
\tableofcontents

\section{Définitions}
\subsection{Neurone}
Un Neurone est une représentation mathématique et informatique d'un neurone biologique. Il contient en général plusieurs entrées et une seule sortie.
Mathématiquement, un neurone est une fonction à plusieurs variables et à valeurs réelles.

\subsection{Réseau de Neurones}
Un réseau de Neurones est une association de neurones pour accomplir des tâches arbitrairement complexes.

\subsection{Fonction d'activation}
Une fonction d'activation (souvent notée $\sigma$) est une fonction de $\mathbb{R^R}$ dont son calcul et celui de sa dérivée est peu couteux en temps. Choisir des fonctions d'activations non-linéaires permet au réseau de créer des comportements plus complexes.

\section{Notations}
\begin{figure}[H]
	\includegraphics[width=\linewidth]{Réseau.jpeg}
	\caption{Réseau simple à trois couches}
	\label{fig:Réseau}
\end{figure}

\subsection{Poids}
\[w_{i,j}^{\ell}\] est le poids reliant le neurone $i$ de la couche $\ell$ au neurone $j$ de la couche $\ell+1$

\subsection{Activation intermédiaire}
Considérons une couche $\ell \in \mathbb{N}$ d'un réseau. Notons $n$ le nombre de neurones dans la couche $\ell$.
Pour le neurone $i$ de la couche $\ell+1$, on définit sa valeur d'activation intermédiaire:
\begin{equation} 
\label{eq:1}
z_{i}^{\ell+1} = \sum_{k=1}^n{w_{k,i}^{\ell}a_k^{\ell}}
\end{equation}

\subsection{Biais}
\[b_{i}^\ell\] est la valeur du biais $i$ de la couche $l$.

\subsection{Fonction d'activation}
\[\sigma^{\ell}:\] est la fonction d'activation permettant de passer de la couche $\ell - 1$ à la couche $\ell$.

\subsection{Activation}
\[a_{i}^\ell\] est la valeur du neurone $i$ de la couche $\ell$. Elle vaut $\sigma(z_{i}^\ell)$

\subsection{Matrice d'activation}
\begin{align*}
A_\ell =
\begin{pmatrix} a_1^\ell & a_2^\ell & ... & a_n^\ell
\end{pmatrix}
\end{align*}

\subsection{Matrice d'activations intermédiaires}
\begin{align*}
Z_\ell =
\begin{pmatrix} z_1^\ell & z_2^\ell & ... & z_n^\ell
\end{pmatrix}
\end{align*}

\subsection{Matrice des poids}
\begin{align*}
W_{\ell} =
\begin{pmatrix} w_{1, 1}^\ell & w_{1,2}^\ell & ... & w_{1,k}^\ell \\ 
w_{2,1}^\ell & w_{2,2}^\ell & ... & w_{2,k}^\ell \\
... & ... & ... & ... \\
w_{n,1}^\ell & w_{n,2}^\ell & ... & w_{n,k}^\ell
\end{pmatrix}
\end{align*}
Où $n$ est le nombre de neurones dans la couche $\ell$ et $k$ dans la couche $\ell+1$

\subsection{Matrice gradient}
Pour une matrice $M_{\ell}$, on note $\nabla_M^{\ell}$ la matrice des dérivées partielles par rapport a chacun des coefficients.
Par exemple: 
\[\nabla_A^{\ell} = \begin{pmatrix} \frac{\partial}{\partial a_1^\ell} & \frac{\partial}{\partial a_2^\ell} & ... & \frac{\partial}{\partial a_n^\ell} \end{pmatrix}\]

\subsection{Matrice $\delta$}
On pose $\delta^{\ell} = \nabla_Z^{\ell}C$

\subsection{Produit de Hadamard}
L'operateur $\odot$ permet de definir le produit de Hadamard: le produit matriciel terme a terme:
\begin{align*}
\begin{pmatrix} a_{1,1} & a_{1,2} \\
a_{2,1} & a_{2,2}
\end{pmatrix}
\odot
\begin{pmatrix} b_{1,1} & b_{1,2} \\
b_{2,1} & b_{2,2}
\end{pmatrix}=
\begin{pmatrix} a_{1,1} \cdot b_{1,1} & a_{1,2} \cdot b_{1,2} \\
a_{2,1} \cdot b_{2,1} & a_{2,2} \cdot b_{2,2}
\end{pmatrix}
\end{align*}

\section{Formules de propagation}
\subsection{Propagation avant}
L'équation \eqref{eq:1} et la définition de $Z_{\ell}$ peuvent être mises sous forme matricielle pour donner:
\begin{equation}
\label{fp1}
Z_{\ell+1}= A_\ell \cdot W_\ell+B_{\ell+1}
\end{equation}
\begin{equation}
\label{fp2}
A_{\ell+1}= \sigma(Z_{\ell+1})
\end{equation}

\subsection{Propagation arrière}
Par le théorème de dérivation des fonctions composées, on a:

\[\frac{\partial C}{\partial z_j^\ell}=\frac{\partial C}{\partial a_j^\ell} \cdot \frac{\partial a_j^\ell}{\partial z_j^\ell}=\frac{\partial C}{\partial a_j^\ell} \sigma'(z_j^\ell)\]

Ce qui permet d'obtenir une première equation de rétro-propagation:
\begin{equation}
\label{bp1}
\delta^\ell=\nabla_a^\ell C \odot \sigma'(Z_\ell)
\end{equation}

Puis,
\begin{equation}
\label{bp2}
\nabla_a^{\ell} C = \delta^{\ell+1} \cdot (W_\ell)^T 
\end{equation}

Les equations \eqref{bp1} et \eqref{bp2} permettent d'établir une relation de récurrence descendante sur la suite $(\delta^{\ell})_{\ell \in \mathbb{N}}$:

\begin{equation}
\delta^{\ell} = (\delta^{\ell+1} \cdot (W_\ell)^T) \odot \sigma'(Z_\ell)
\end{equation}

En appliquant une seconde fois ce théorème, on effectue le calcul matriciel suivant:
\begin{align*}
\nabla_w^\ell C &= \begin{pmatrix} \frac{\partial C}{\partial w_{1, 1}^\ell} & \frac{\partial C}{\partial w_{1,2}^\ell} & ... & \frac{\partial C}{\partial w_{1,k}^\ell} \\ \frac{\nabla C}{\partial w_{2,1}^{\ell}} & \frac{\partial C}{\partial w_{2,2}^{\ell}} & ... & \frac{\partial C}{\partial w_{2,k}^{\ell}} \\
... & ... & ... & ... \\
\frac{\partial C}{\partial w_{n,1}^\ell} & \frac{\partial C}{\partial w_{n,2}\ell} & ... & \frac{\partial C}{\partial w_{n,k}\ell}
\end{pmatrix} \\
&=\begin{pmatrix} \frac{\partial C}{\partial z_1^{\ell+1}} \cdot \frac{\partial z_1^{\ell+1}}{\partial w_{1, 1}^\ell} & \frac{\partial C}{\partial z_2^{\ell+1}} \cdot \frac{\partial z_2^{\ell+1}}{\partial w_{1, 2}^\ell} & ... & \frac{\partial C}{\partial z_k^{\ell+1}} \cdot \frac{\partial z_k^{\ell+1}}{\partial w_{1, k}^\ell} \\ 
\frac{\partial C}{\partial z_1^{\ell+1}} \cdot \frac{\partial z_1^{\ell+1}}{\partial w_{2, 1}^\ell} & \frac{\partial C}{\partial z_2^{\ell+1}} \cdot \frac{\partial z_2^{\ell+1}}{\partial w_{2, 2}^\ell} & ... & \frac{\partial C}{\partial a_k^{\ell+1}} \cdot \frac{\partial z_k^{\ell+1}}{\partial w_{2, k}^\ell} \\
... & ... & ... & ... \\
\frac{\partial C}{\partial z_1^{\ell+1}} \cdot \frac{\partial z_1^{\ell+1}}{\partial w_{n, 1}^\ell} & \frac{\partial C}{\partial z_2^{\ell+1}} \cdot \frac{\partial z_2^{\ell+1}}{\partial w_{n, 2}^\ell} & ... & \frac{\partial C}{\partial z_k^{\ell+1}} \cdot \frac{\partial z_k^{\ell+1}}{\partial w_{n, k}^\ell}
\end{pmatrix} \\
&=\begin{pmatrix}
\nabla_z^{\ell+1}C \cdot a_1^\ell \\
\nabla_z^{\ell+1}C \cdot a_2^\ell \\
... \\
\nabla_z^{\ell+1}C \cdot a_n^\ell
\end{pmatrix} \\
&=\begin{pmatrix}
\delta^{\ell+1} \cdot a_1^\ell \\
\delta^{\ell+1} \cdot a_2^\ell \\
... \\
\delta^{\ell+1} \cdot a_n^\ell
\end{pmatrix} \\
&= \begin{pmatrix}
\delta^{\ell+1}\\
\delta^{\ell+1}\\
... \\
\delta^{\ell + 1}
\end{pmatrix} \odot (A_\ell)^T
\end{align*}

On obtient ainsi:
\begin{equation}
\label{bp3}
\nabla_w^\ell C = \begin{pmatrix}
\delta^{\ell+1}\\
\delta^{\ell+1}\\
... \\
\delta^{\ell + 1}
\end{pmatrix} \odot (A_\ell)^T
\end{equation}

Par un calcul analogue, on obtient:
\begin{equation}
\label{bp4}
\nabla_b^\ell C = \delta^{\ell}
\end{equation}

\section{Descente de gradient}
\subsection{Principe}


\end{document}









